@article{FarreletalECTA16901,
author = {Farrell, Max H. and Liang, Tengyuan and Misra, Sanjog},
title = {Deep Neural Networks for Estimation and Inference},
journal = {Econometrica},
volume = {89},
number = {1},
pages = {181-213},
keywords = {Deep learning, neural networks, rectified linear unit, nonasymptotic bounds, convergence rates, semiparametric inference, treatment effects, program evaluation},
doi = {https://doi.org/10.3982/ECTA16901},
url = {https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA16901},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.3982/ECTA16901},
abstract = {We study deep neural networks and their use in semiparametric inference. We establish novel nonasymptotic high probability bounds for deep feedforward neural nets. These deliver rates of convergence that are sufficiently fast (in some cases minimax optimal) to allow us to establish valid second-step inference after first-step estimation with deep learning, a result also new to the literature. Our nonasymptotic high probability bounds, and the subsequent semiparametric inference, treat the current standard architecture: fully connected feedforward neural networks (multilayer perceptrons), with the now-common rectified linear unit activation function, unbounded weights, and a depth explicitly diverging with the sample size. We discuss other architectures as well, including fixed-width, very deep networks. We establish the nonasymptotic bounds for these deep nets for a general class of nonparametric regression-type loss functions, which includes as special cases least squares, logistic regression, and other generalized linear models. We then apply our theory to develop semiparametric inference, focusing on causal parameters for concreteness, and demonstrate the effectiveness of deep learning with an empirical application to direct mail marketing.},
year = {2021}
}


@misc{ZhangetalBook,
  doi = {10.48550/ARXIV.2106.11342},
  
  url = {https://arxiv.org/abs/2106.11342},
  
  author = {Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Dive into Deep Learning},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@misc{Bartlettetal2021Arxiv,
  doi = {10.48550/ARXIV.2103.09177},
  
  url = {https://arxiv.org/abs/2103.09177},
  
  author = {Bartlett, Peter L. and Montanari, Andrea and Rakhlin, Alexander},
  
  keywords = {Statistics Theory (math.ST), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Deep learning: a statistical viewpoint},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}
@misc{BottouetalArxiv2016,
  doi = {10.48550/ARXIV.1606.04838},
  
  url = {https://arxiv.org/abs/1606.04838},
  
  author = {Bottou, Léon and Curtis, Frank E. and Nocedal, Jorge},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), Optimization and Control (math.OC), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  
  title = {Optimization Methods for Large-Scale Machine Learning},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{mcculloch43a,
  added-at = {2008-02-26T11:58:58.000+0100},
  author = {Mcculloch, Warren and Pitts, Walter},
  biburl = {https://www.bibsonomy.org/bibtex/26fbacb0ae04bc17d296d9265dfc90dff/schaul},
  citeulike-article-id = {2380493},
  description = {idsia},
  interhash = {3e8e0d06f376f3eb95af89d5a2f15957},
  intrahash = {6fbacb0ae04bc17d296d9265dfc90dff},
  journal = {Bulletin of Mathematical Biophysics},
  keywords = {evolutionary},
  pages = {127--147},
  priority = {2},
  timestamp = {2008-02-26T12:00:58.000+0100},
  title = {A Logical Calculus of Ideas Immanent in Nervous Activity},
  volume = 5,
  year = 1943
}

@article{Rosenblatt1958ThePA,
  title={The perceptron: a probabilistic model for information storage and organization in the brain.},
  author={Frank Rosenblatt},
  journal={Psychological review},
  year={1958},
  volume={65 6},
  pages={
          386-408
        }
}

@article{AtheyImbensARE2019,
author = {Athey, Susan and Imbens, Guido W.},
title = {Machine Learning Methods That Economists Should Know About},
journal = {Annual Review of Economics},
volume = {11},
number = {1},
pages = {685-725},
year = {2019}
}
@article{MullainathanSpiessJEP2017,
Author = {Mullainathan, Sendhil and Spiess, Jann},
Title = {Machine Learning: An Applied Econometric Approach},
Journal = {Journal of Economic Perspectives},
Volume = {31},
Number = {2},
Year = {2017},
Month = {May},
Pages = {87-106}
}

@article{GentzkowEtalEcta2019,
author = {Gentzkow, Matthew and Shapiro, Jesse M. and Taddy, Matt},
title = {Measuring Group Differences in High-Dimensional Choices: Method and Application to Congressional Speech},
journal = {Econometrica},
volume = {87},
number = {4},
pages = {1307-1340},
year = {2019}
}

@article{ChernozhukovEtalAER2017,
Author = {Chernozhukov, Victor and Chetverikov, Denis and Demirer, Mert and Duflo, Esther and Hansen, Christian and Newey, Whitney},
Title = {Double/Debiased/Neyman Machine Learning of Treatment Effects},
Journal = {American Economic Review},
Volume = {107},
Number = {5},
Year = {2017},
Month = {May},
Pages = {261-65}
}

@article{CoulombeEtalJAE2022,
author = {Goulet Coulombe, Philippe and Leroux, Maxime and Stevanovic, Dalibor and Surprenant, Stéphane},
title = {How is machine learning useful for macroeconomic forecasting?},
journal = {Journal of Applied Econometrics},
volume = {37},
number = {5},
pages = {920-964},
year = {2022}
}

@article{AzinovicEtalIER2022,
author = {Azinovic, Marlon and Gaegauf, Luca and Scheidegger, Simon},
title = {DEEP EQUILIBRIUM NETS},
journal = {International Economic Review},
volume = {63},
number = {4},
pages = {1471-1525},
year = {2022}
}

@misc{FinanPouzoArxiv2021,
 author = {Finan, Frederico and Pouzo, Demian},
  title = {Reinforcing RCTs with Multiple Priors while Learning about External Validity},
  publisher = {arXiv},
  year = {2021}
}

@misc{ChernozhukovEtalArxiv2021,
  author = {Chernozhukov, Victor and Newey, Whitney K. and Quintas-Martinez, Victor and Syrgkanis, Vasilis},
  title = {RieszNet and ForestRiesz: Automatic Debiased Machine Learning with Neural Nets and Random Forests},
  publisher = {arXiv},
  year = {2021}
}

@inproceedings{HartfordEtalProced2017,
author = {Hartford, Jason and Lewis, Greg and Leyton-Brown, Kevin and Taddy, Matt},
title = {Deep IV: A Flexible Approach for Counterfactual Prediction},
year = {2017},
publisher = {JMLR.org},
booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
pages = {1414–1423},
numpages = {10},
location = {Sydney, NSW, Australia},
series = {ICML'17}
}

